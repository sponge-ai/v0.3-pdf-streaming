- removed print logging
- moved client = OpenAI() outside post()
- added time logging

File read: 0.00s
OpenAI upload: 1.60s
OpenAI response: 63.04s
Total: 64.64s

- uvicorn server:app --reload
+ uvicorn server:app --host 127.0.0.1 --port 8000

File read: 0.00s
OpenAI upload: 1.56s
OpenAI response: 73.61s
Total: 75.16s

- uvicorn server:app --workers 4

File read: 0.00s
OpenAI upload: 1.39s
OpenAI response: 84.08s
Total: 85.48s

- uvicorn server:app

File read: 0.00s
OpenAI upload: 1.79s
OpenAI response: 111.73s
Total: 113.52s

# ChatGPT: bottleneck is OpenAI servers
not fastapi / uvicorn or local setup

